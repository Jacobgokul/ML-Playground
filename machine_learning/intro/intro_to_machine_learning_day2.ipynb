{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVBtZzd8CA6Yq5z2r96i7i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacobgokul/ML-Playground/blob/main/Day_2_Intro_to_Machine_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning\n",
        "\n",
        "Machine learning (ML) is a branch of artificial intelligence (AI) that focuses on enabling machines to learn from data without being explicitly programmed. Essentially, it's about building systems that improve their performance as they are exposed to more data"
      ],
      "metadata": {
        "id": "lDj4gFlTp1u_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Types of ML\n",
        "- Supervised Learning\n",
        "- UnSupervised Learning\n",
        "- Reinforcement Learning"
      ],
      "metadata": {
        "id": "NiAvP6T2qXr5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üß† 1. Supervised Learning\n",
        "You train the model on labeled data (input + correct output).\n",
        "\n",
        "üîπ Categories:\n",
        "‚úÖ Regression (predicting continuous values)\n",
        "\n",
        "- Linear Regression\n",
        "\n",
        "- Ridge / Lasso Regression\n",
        "\n",
        "- Decision Tree Regressor\n",
        "\n",
        "- Random Forest Regressor\n",
        "\n",
        "- Support Vector Regressor\n",
        "\n",
        "- K-Nearest Neighbors (KNN) Regressor\n",
        "\n",
        "‚úÖ Classification (predicting categories/labels)\n",
        "\n",
        "- Logistic Regression\n",
        "\n",
        "- Decision Tree Classifier\n",
        "\n",
        "- Random Forest Classifier\n",
        "\n",
        "- K-Nearest Neighbors (KNN) Classifier\n",
        "\n",
        "- Support Vector Machine (SVM)\n",
        "\n",
        "- Naive Bayes\n",
        "\n",
        "- Gradient Boosting (XGBoost, LightGBM)\n",
        "\n",
        "üß© 2. Unsupervised Learning\n",
        "\n",
        "You train the model on unlabeled data (no known output).\n",
        "\n",
        "üîπ Categories:\n",
        "\n",
        "‚úÖ Clustering (grouping similar items)\n",
        "\n",
        "- K-Means\n",
        "\n",
        "- DBSCAN\n",
        "\n",
        "- Hierarchical Clustering\n",
        "\n",
        "- Mean Shift\n",
        "\n",
        "‚úÖ Dimensionality Reduction (reducing number of features)\n",
        "\n",
        "- PCA (Principal Component Analysis)\n",
        "\n",
        "- t-SNE (t-Distributed Stochastic Neighbor Embedding)\n",
        "\n",
        "- LDA (Linear Discriminant Analysis)\n",
        "\n",
        "- Autoencoders (Neural networks for compression)\n",
        "\n",
        "üïπÔ∏è 3. Reinforcement Learning\n",
        "\n",
        "An agent learns by taking actions in an environment and receiving rewards.\n",
        "\n",
        "üîπ Categories:\n",
        "\n",
        "‚úÖ Agent-Based Decision Making\n",
        "\n",
        "- Q-Learning\n",
        "\n",
        "- Deep Q Networks (DQN)\n",
        "\n",
        "- SARSA (State-Action-Reward-State-Action)\n",
        "\n",
        "- Policy Gradient Methods\n",
        "\n",
        "- Actor-Critic Methods\n",
        "\n",
        "üîÑ 4. Semi-Supervised Learning\n",
        "\n",
        "Uses small amount of labeled data + large unlabeled data.\n",
        "\n",
        "Used when labeling data is expensive.\n",
        "\n",
        "üîπ Common Algorithms\n",
        "\n",
        "- Self-Training Classifier\n",
        "\n",
        "- Label Propagation\n",
        "\n",
        "- Semi-Supervised SVM\n",
        "\n",
        "- Pseudo-labeling\n",
        "\n"
      ],
      "metadata": {
        "id": "fD4BiiEQqogG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RA47niIyqGVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "HxOoGknH9A2c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What is Ensemble Learning?\n",
        "\n",
        "Ensemble = Combining multiple models to create a better one.\n",
        "\n",
        "##  Why Use It?\n",
        "üìà Improves accuracy\n",
        "\n",
        "üß† Reduces overfitting or underfitting\n",
        "\n",
        "üîÑ Works better than single models (most of the time)\n",
        "\n",
        "## Types of Ensemble Learning:\n",
        "### Bagging (Bootstrap Aggregating)\n",
        "üìå What:\n",
        "\n",
        "Trains many models on random subsets of the data (with replacement)\n",
        "\n",
        "Then combines their predictions (average for regression, majority vote for classification)\n",
        "\n",
        "üí° Example:\n",
        "\n",
        "Random Forest = Bagging of Decision Trees\n",
        "\n",
        "ü§ñ When to Use:\n",
        "\n",
        "When you want to reduce variance (i.e., the model is overfitting)\n",
        "\n",
        "Works great with high-variance models like decision trees\n",
        "\n",
        "üß™ Real Example:\n",
        "\n",
        "Random Forest Classifier\n",
        "\n",
        "Random Forest Regressor\n",
        "\n",
        "### Boosting\n",
        "\n",
        "üìå What:\n",
        "\n",
        "Trains models one after another, where each new model fixes the errors made by the previous one.\n",
        "\n",
        "Models are added sequentially (not parallel like bagging)\n",
        "\n",
        "üìà Goal:\n",
        "\n",
        "Focus more on hard-to-predict data\n",
        "\n",
        "ü§ñ When to Use:\n",
        "\n",
        "When you want to reduce bias and build strong predictive models\n",
        "\n",
        "üî• Popular Algorithms:\n",
        "\n",
        "AdaBoost\n",
        "\n",
        "Gradient Boosting\n",
        "\n",
        "XGBoost (Extreme Gradient Boosting)\n",
        "\n",
        "LightGBM (Light Gradient Boosting)\n",
        "\n",
        "CatBoost (for categorical data)\n",
        "\n",
        "üß™ Real Example:\n",
        "\n",
        "XGBoost Classifier / Regressor\n",
        "\n",
        "LightGBM Classifier / Regressor"
      ],
      "metadata": {
        "id": "YJVDMIpO9CLq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nDl4C21v9BZs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}