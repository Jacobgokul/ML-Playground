{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f000079",
   "metadata": {},
   "source": [
    "## What is LSTM?\n",
    "- LSTM stands for Long Short-Term Memory.\n",
    "\n",
    "- It’s a type of Recurrent Neural Network (RNN) designed to remember information for long sequences.\n",
    "\n",
    "- Unlike a regular RNN, LSTMs can remember dependencies across longer time periods without forgetting earlier inputs.\n",
    "\n",
    "- LSTM uses gates to control the flow of information, deciding what to remember, forget, and output at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8309ea06",
   "metadata": {},
   "source": [
    "## Why Use LSTM?\n",
    "- Standard RNNs struggle with vanishing gradients, meaning they forget information from earlier steps in long sequences.\n",
    "\n",
    "- LSTM solves this with a special memory structure called cell state and gates that control what to keep, forget, or output.\n",
    "\n",
    "- Can be used for:\n",
    "\n",
    "    - Text generation\n",
    "\n",
    "    - Language modeling\n",
    "\n",
    "    - Speech recognition\n",
    "\n",
    "    - Time series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d95dc45",
   "metadata": {},
   "source": [
    "## Key Concepts\n",
    "1. Cell State:\n",
    "\n",
    "    - Think of it as a “conveyor belt” that carries important information through the sequence.\n",
    "\n",
    "    - Information can flow unchanged, so the network doesn’t forget everything at each step.\n",
    "\n",
    "2. Hidden State:\n",
    "\n",
    "    - Similar to RNN’s hidden state, it stores the output of the current step and passes it forward.\n",
    "\n",
    "3. Gates:\n",
    "LSTM has three main gates to control the flow of information:\n",
    "\n",
    "    - Forget Gate: Decides what past information to throw away.\n",
    "\n",
    "    - Input Gate: Decides what new information to add to the cell state.\n",
    "\n",
    "    - Output Gate: Decides what information to output at the current step.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa41a171",
   "metadata": {},
   "source": [
    "## How LSTM Works\n",
    "- At each step, input data is combined with the previous hidden state.\n",
    "\n",
    "- The forget gate removes irrelevant information from the cell state.\n",
    "\n",
    "- The input gate adds new, relevant information to the cell state.\n",
    "\n",
    "- The cell state now holds the updated memory.\n",
    "\n",
    "- The output gate decides what information from the cell state to pass on as output.\n",
    "\n",
    "- Repeat for each step in the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262bb1a",
   "metadata": {},
   "source": [
    "### Difference between RNN and LSTM\n",
    "\n",
    "| Feature                | RNN        | LSTM                       |\n",
    "| ---------------------- | ---------- | -------------------------- |\n",
    "| Memory                 | Short-term | Long-term (via cell state) |\n",
    "| Gates                  | None       | Input, Forget, Output      |\n",
    "| Handles long sequences | Poor       | Excellent                  |\n",
    "| Vanishing gradient     | Yes        | No (better stability)      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439434be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16bca768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Example corpus\n",
    "corpus = [\n",
    "    \"hello how are you\",\n",
    "    \"hello how is your day\",\n",
    "    \"hello how are your friends\",\n",
    "    \"hello what are you doing\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c03ce994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique words: 11\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Tokenize the text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1  # +1 because indexing starts from 1\n",
    "print(\"Total unique words:\", total_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5176a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example sequence: [1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create input sequences\n",
    "input_sequences = []\n",
    "\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]  # Take first i+1 words\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Check an example\n",
    "print(\"Example sequence:\", input_sequences[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0292ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example X[0]: [0 0 0 1] -> y[0]: 2\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Pad sequences to same length\n",
    "max_seq_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_seq_len, padding='pre'))\n",
    "\n",
    "# Split inputs (X) and labels (y)\n",
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "\n",
    "print(\"Example X[0]:\", X[0], \"-> y[0]:\", y[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8080e",
   "metadata": {},
   "source": [
    "All sequences must be the same length.\n",
    "\n",
    "padding='pre' adds zeros at the beginning of shorter sequences.\n",
    "\n",
    "X contains input words, y contains the next word to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3110aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\A Code\\ML-Playground\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Build LSTM Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=total_words, output_dim=10, input_length=max_seq_len-1))\n",
    "model.add(LSTM(50, activation='tanh'))  # LSTM layer\n",
    "model.add(Dense(total_words, activation='softmax'))  # Predict next word\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289df36",
   "metadata": {},
   "source": [
    "Embedding layer: Converts integers to dense vectors (meaningful representations).\n",
    "\n",
    "LSTM layer: Learns patterns in sequences.\n",
    "\n",
    "Dense + Softmax: Predicts probability for each word.\n",
    "\n",
    "Loss: sparse_categorical_crossentropy because y is integer-coded.\n",
    "\n",
    "Optimizer: Adam, for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4422956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Train the model\n",
    "history = model.fit(X, y, epochs=200, verbose=0)\n",
    "print(\"Training complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e8c37b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 'hello how is' → Predicted next word: 'your'\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Predict next word\n",
    "def predict_next_word_lstm(model, tokenizer, text_seq, max_seq_len):\n",
    "    token_list = tokenizer.texts_to_sequences([text_seq])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_seq_len-1, padding='pre')\n",
    "    predicted = model.predict(token_list, verbose=0)\n",
    "    predicted_word_index = np.argmax(predicted)\n",
    "    \n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted_word_index:\n",
    "            return word\n",
    "\n",
    "# Test\n",
    "seed_text = \"hello how is\"\n",
    "next_word = predict_next_word_lstm(model, tokenizer, seed_text, max_seq_len)\n",
    "print(f\"Input: '{seed_text}' → Predicted next word: '{next_word}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03c004f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,200</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">561</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m10\u001b[0m)          │           \u001b[38;5;34m110\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)             │        \u001b[38;5;34m12,200\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m)             │           \u001b[38;5;34m561\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,615</span> (150.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,615\u001b[0m (150.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">12,871</span> (50.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m12,871\u001b[0m (50.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,744</span> (100.57 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m25,744\u001b[0m (100.57 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1531aa8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
