{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacobgokul/ML-Playground/blob/main/Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a55FBdbQs4Q6"
      },
      "source": [
        "**Prompt engineering** is the practice of designing and refining prompts to effectively communicate with a large language model (LLM) like ChatGPT, Claude, Gemini, or other generative AI models. It's a core skill for getting accurate, relevant, and useful outputs from AI systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-ogos-8tAny"
      },
      "source": [
        "##  What Is a \"Prompt\"?\n",
        "A prompt is any input text or instruction you give to an AI model. For example:\n",
        "\n",
        "```\n",
        "\"Summarize this article in 3 bullet points.\"\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXbl67-_tIu2"
      },
      "source": [
        "## Why Prompt Engineering Matters\n",
        "\n",
        "LLMs are sensitive to wording, structure, and context. A poorly crafted prompt might lead to:\n",
        "\n",
        "- Vague or irrelevant answers\n",
        "\n",
        "- Overly verbose or under-detailed responses\n",
        "\n",
        "- Misinterpretation of your intent\n",
        "\n",
        "Prompt engineering helps optimize the interaction so the model:\n",
        "\n",
        "- Understands the task correctly\n",
        "\n",
        "- Stays within the desired tone, format, or constraints\n",
        "\n",
        "- Produces consistent and reliable results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How to write a good prompt.\n",
        "- Define the Role – Tell the model who it is or how to behave.\n",
        "\n",
        "- State the Goal Clearly – Specify exactly what you want done.\n",
        "\n",
        "- Provide Context or Constraints – Give necessary details, limits, or preferences.\n",
        "\n",
        "- Specify Output Format – Indicate how the answer should be structured (table, JSON, bullet points, etc.).\n",
        "\n",
        "- Control Style or Tone (Optional) – Decide if the response should be formal, casual, technical, or creative.\n",
        "\n",
        "- Ask for Missing Information (Optional) – Let the model request info if something is unclear.\n",
        "\n",
        "- Test and Refine – Run the prompt, check outputs, and tweak instructions for consistency.\n",
        "\n",
        "- Keep it Clear and Concise – Avoid ambiguity or overly long instructions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rkSsLUyqt659"
      },
      "outputs": [],
      "source": [
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant.\" # Explaining the system (AI Model) who are you and what you need to do\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Who won the world series in 2020?\" # its an user query or input\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20nXQdUQt6aE"
      },
      "source": [
        "# Type of Prompting\n",
        "\n",
        "## Zero-shot Prompting\n",
        "- Zero-shot prompting is when you ask the AI to perform a task without giving any examples — only clear instructions.\n",
        "    - The model relies purely on its pre-trained knowledge and the clarity of your command.\n",
        "\n",
        "    - It’s useful when the task is simple, direct, or widely known.\n",
        "\n",
        "    - Works best if your instruction includes the goal, format, and tone you expect.\n",
        "\n",
        "    - No pattern-learning from examples — the model figures it out from the instruction alone\n",
        "\n",
        "\n",
        "```py\n",
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "            Goal: You are a trip planner. Your job is to help users plan their trips and create itineraries.\n",
        "            Instructions:\n",
        "            - Ask the user if they already have a destination in mind.\n",
        "            - Create the trip plan based on their preferences, duration, and budget.\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One-Shot prompting\n",
        "- One-shot prompting is when you provide only one example of the task before asking the AI to perform it.\n",
        "    - The single example shows the pattern of response.\n",
        "\n",
        "    - Helps the model understand formatting, style, or tone.\n",
        "\n",
        "    - Useful when you want a consistent output but don’t want to give multiple examples.\n",
        "\n",
        "```py\n",
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "            {\n",
        "                \"goal\": \"You are a fitness coach chatbot. Provide exercise plans, diet tips, and health advice. If the user asks something unrelated to fitness, respond with 'I'm a Fitness chatbot'.\",\n",
        "\n",
        "                \"examples\": [\n",
        "                    {\n",
        "                    \"user_query\": \"Create a 3-day workout plan for beginners\",\n",
        "                    \"AI_answer\": \"Day 1: 20 min cardio, 15 min bodyweight exercises. Day 2: Rest. Day 3: 20 min strength training, 10 min stretching.\"\n",
        "                    }\n",
        "                ],\n",
        "\n",
        "                \"output_format\": \n",
        "                {\n",
        "                    \"question\": \"\", // User query exactly as asked\n",
        "                    \"Answer\": \"\" // AI response according to the query\n",
        "                }\n",
        "            }\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHEb5VM0tvK7"
      },
      "source": [
        "## Few-Shot prompting\n",
        "- Few-shot prompting is a technique where you give the AI a few examples of the task you want it to perform before asking your actual question.\n",
        "  - Helps the model learn patterns from examples.\n",
        "\n",
        "  - Useful when instructions alone aren’t enough.\n",
        "\n",
        "```py\n",
        "prompt = [\n",
        "    \"role\": \"system\",\n",
        "    \"content\": \"\"\"\n",
        "      {\n",
        "        \"goal\": \"You are a helpful programming chatbot. Solve programming queries and provide answers in JSON or dictionary format, stick to the output format mentioned. If the user asks something unrelated to programming, respond with 'I'm a Programming chatbot'.\",\n",
        "\n",
        "        \"examples\": [\n",
        "          {\n",
        "            \"user_query\": \"what is python\",\n",
        "            \"AI_answer\": \"Python is a high-level programming language used for AI, web development, and automation.\"\n",
        "          },\n",
        "          {\n",
        "            \"user_query\": \"explain about IPL\",\n",
        "            \"AI_answer\": \"I'm a Programming chatbot\"\n",
        "          }\n",
        "        ]\n",
        "      }\n",
        "\n",
        "      \"output_format\": \n",
        "        {\n",
        "          \"question\": \"\", // Provide user query here without changing single word\n",
        "          \"Answer\": \"\" // provide your answer respective to the query asked by user.\n",
        "        }\n",
        "    \"\"\"\n",
        "]\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chain-of-Thought (CoT) Prompting\n",
        "Chain-of-Thought prompting is a technique where you instruct the model to think step by step before giving the final answer. Instead of expecting the answer directly, the model explains its reasoning, which improves accuracy, especially for multi-step problems.\n",
        "\n",
        "#### Why it works:\n",
        "- LLMs are good at pattern recognition but sometimes skip reasoning steps.\n",
        "\n",
        "- By asking them to \"show reasoning,\" you guide the model to simulate logical thinking.\n",
        "\n",
        "- Useful for math problems, logic puzzles, reasoning tasks, or any task requiring multiple steps.\n",
        "\n",
        "\n",
        "#### How CoT Works\n",
        "Instead of this:\n",
        "\n",
        "```text\n",
        "Q: If there are 3 apples and I buy 2 more, how many apples do I have?\n",
        "A: 5\n",
        "```\n",
        "\n",
        "You do:\n",
        "\n",
        "```text\n",
        "Q: If there are 3 apples and I buy 2 more, how many apples do I have? Show your reasoning.\n",
        "A: \n",
        "Step 1: Start with 3 apples.\n",
        "Step 2: Buy 2 more apples.\n",
        "Step 3: Total apples = 3 + 2 = 5\n",
        "Answer: 5\n",
        "```\n",
        "\n",
        "Here, the model breaks the problem into steps before answering. This makes it more accurate for complex problems.\n",
        "\n",
        "#### How to Design a CoT Prompt\n",
        "Key principles:\n",
        "\n",
        "1. Explicitly ask for reasoning.\n",
        "\n",
        "    - Words like: “Explain your reasoning,” “Step by step,” “Show how you got the answer.”\n",
        "\n",
        "2. Provide examples (few-shot) if possible.\n",
        "\n",
        "    - Helps the model understand how to format reasoning.\n",
        "\n",
        "3. Keep instructions clear and simple.\n",
        "\n",
        "    - Don’t mix multiple goals in one prompt.\n",
        "\n",
        "4. Guide the format of output (optional).\n",
        "\n",
        "    - Like “List steps 1, 2, 3, and then give final answer.”\n",
        "\n",
        "\n",
        "```py\n",
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"\"\"\n",
        "            Goal: You are a helpful assistant. Always solve problems by explaining your reasoning step by step.\n",
        "\n",
        "            Example 1:\n",
        "            Q: If I have 2 pencils and buy 3 more, how many pencils do I have? Explain.\n",
        "            A:\n",
        "            Step 1: Start with 2 pencils.\n",
        "            Step 2: Buy 3 more pencils.\n",
        "            Step 3: Total = 2 + 3 = 5\n",
        "            Answer: 5\n",
        "        \"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "            Now solve this:\n",
        "                Q: A bookstore sold 15 books on Monday and 20 books on Tuesday. How many books did it sell in total? Explain.\n",
        "                A:    \n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "```\n",
        "\n",
        "\n",
        "##### Expected output\n",
        "Step 1: Books sold on Monday = 15\n",
        "\n",
        "Step 2: Books sold on Tuesday = 20\n",
        "\n",
        "Step 3: Total books sold = 15 + 20 = 35\n",
        "\n",
        "Answer: 35"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd69N5crdeqD"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIYf5gnOdh_W"
      },
      "source": [
        "## Core Principles of a Good Prompt\n",
        "\n",
        "1. Be Clear and Specific\n",
        "\n",
        "- Clearly define the task.\n",
        "\n",
        "- Include context or constraints.\n",
        "\n",
        "- Specify the desired format/output.\n",
        "\n",
        "```\n",
        "❌ Bad:\n",
        "\n",
        "“Summarize this.”\n",
        "\n",
        "✅ Good:\n",
        "\n",
        "“Summarize the following text into 3 bullet points highlighting only the main arguments.”\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bv3vaZEchG67"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxKGAQy-hIDC"
      },
      "source": [
        "# How AI Model understand or process the text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xA0R68NdfF3"
      },
      "source": [
        "Gokul was an Ai Engineer working in southern part of india located in coimbatore he has 5 years experince in the field of python along with AI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUSHTugkiwiH"
      },
      "source": [
        "## 1. Input Encoding (Tokenization)\n",
        "Every word (and even part of a word) is broken into tokens. For example:\n",
        "```\n",
        "[\"Gokul\", \"was\", \"an\", \"AI\", \"Engineer\", \"working\", \"in\", \"southern\", \"part\", \"of\", \"India\", \"located\", \"in\", \"Coimbatore\", \".\", \"He\", \"has\", \"5\", \"years\", \"experience\", \"in\", \"the\", \"field\", \"of\", \"Python\", \"along\", \"with\", \"AI\", \".\"]\n",
        "```\n",
        "\n",
        "But most transformers use subword tokenization (like Byte-Pair Encoding or WordPiece), so it may look like this internally:\n",
        "```\n",
        "[\"Gokul\", \"was\", \"an\", \"AI\", \"Engineer\", \"work\", \"##ing\", \"in\", \"south\", \"##ern\", ..., \"Coim\", \"##bato\", \"##re\"]\n",
        "```\n",
        " Why Subword? Helps handle new words, rare names, or spelling variations.\n",
        "\n",
        "\n",
        "##  2. Token Embeddings\n",
        "Each token is converted into a dense vector (say, 768 dimensions) using an embedding matrix.\n",
        "\n",
        "Example:\n",
        "\"Gokul\" → [0.12, -0.44, ..., 0.87]\n",
        "\n",
        "These embeddings capture:\n",
        "\n",
        "- Word meaning\n",
        "\n",
        "- Contextual usage\n",
        "\n",
        "- Semantic closeness (e.g., \"Engineer\" and \"Developer\" are near in space)\n",
        "\n",
        "## 3. Positional Encoding\n",
        "Since transformers don't have loops, position of each token is added (e.g., whether \"Gokul\" came first or last).\n",
        "```\n",
        "Gokul - 1\n",
        "was - 2\n",
        "an - 3\n",
        "AI - 4\n",
        "Engineer - 5\n",
        "...\n",
        "```\n",
        "\n",
        "## 4. Passing Through Transformer Layers\n",
        "The embedded and position-aware tokens pass through multiple transformer blocks, each with:\n",
        "\n",
        "- Self-Attention:\n",
        "\n",
        "    Looks at all other tokens to figure out what to focus on.\n",
        "\n",
        "    → For “He”, the model attends to “Gokul” to know who \"He\" refers to.\n",
        "\n",
        "- Feedforward Layers:\n",
        "\n",
        "    Adds non-linearity and complexity.\n",
        "\n",
        "- Layer Norm & Residuals:\n",
        "    For stability and better learning.\n",
        "\n",
        "## 5. Attention Visualization\n",
        "Let's look at this part of your sentence:\n",
        "```\n",
        "\"He has 5 years experience\"\n",
        "```\n",
        "\n",
        "#### The attention mechanism sees:\n",
        "\n",
        "- “He” → highly connected to “Gokul”\n",
        "\n",
        "- “5 years” → connects with “experience”\n",
        "\n",
        "- “Experience” → strongly linked to “Python” and “AI”\n",
        "\n",
        "## 6. Final Representation\n",
        "After all transformer layers, each token has a contextual vector representing not just the word but its meaning in that sentence.\n",
        "\n",
        "For example:\n",
        "\n",
        "“AI” in “AI Engineer” has a different vector than “AI” in “along with AI”.\n",
        "\n",
        "## 7. Output (Based on Task)\n",
        "Depending on your goal, this final vector is used:\n",
        " - For summarization: The whole sentence vector is pooled and shortened.\n",
        "\n",
        " - For question answering: The model picks the answer span.\n",
        "\n",
        " - For understanding intent or generating a reply (as I do): The next tokens are predicted using all this context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKnrlX0rnyez"
      },
      "source": [
        "# Final Thought:\n",
        "Modern AI models don’t just “see” words.\n",
        "\n",
        "They understand grammar, references, roles, and meanings using:\n",
        "\n",
        "\n",
        "✅ Tokens →\n",
        "✅ Embeddings →\n",
        "✅ Attention →\n",
        "✅ Context →\n",
        "✅ Output\n",
        "\n",
        "All without manually removing stopwords or hardcoded rules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBeONTNnnxwE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyPa+f6yyu/NIgcDdyccw1Cr",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
