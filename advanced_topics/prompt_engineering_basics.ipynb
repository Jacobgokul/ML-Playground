{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa+f6yyu/NIgcDdyccw1Cr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacobgokul/ML-Playground/blob/main/Prompt_Engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt engineering** is the practice of designing and refining prompts to effectively communicate with a large language model (LLM) like ChatGPT, Claude, Gemini, or other generative AI models. It's a core skill for getting accurate, relevant, and useful outputs from AI systems."
      ],
      "metadata": {
        "id": "a55FBdbQs4Q6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  What Is a \"Prompt\"?\n",
        "A prompt is any input text you give to an AI model. For example:\n",
        "\n",
        "```\n",
        "\"Summarize this article in 3 bullet points.\"\n",
        "```"
      ],
      "metadata": {
        "id": "k-ogos-8tAny"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Prompt Engineering Matters\n",
        "\n",
        "LLMs are sensitive to wording, structure, and context. A poorly crafted prompt might lead to:\n",
        "\n",
        "- Vague or irrelevant answers\n",
        "\n",
        "- Overly verbose or under-detailed responses\n",
        "\n",
        "- Misinterpretation of your intent\n",
        "\n",
        "Prompt engineering helps optimize the interaction so the model:\n",
        "\n",
        "- Understands the task correctly\n",
        "\n",
        "- Stays within the desired tone, format, or constraints\n",
        "\n",
        "- Produces consistent and reliable results"
      ],
      "metadata": {
        "id": "OXbl67-_tIu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a helpful assistant.\" # Explaining the system (AI Model) who are you and what you need to do\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Who won the world series in 2020?\" # its an user query or input\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "rkSsLUyqt659"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "20nXQdUQt6aE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Type of Prompting\n",
        "\n",
        "## What is Few-shot Prompting?\n",
        "Few-shot prompting is a technique where you give the model a few examples of what you want it to do before asking your actual question.\n",
        "\n",
        "- It helps the model learn the pattern from the examples.\n",
        "- It's useful when instructions alone are not enough.\n",
        "\n",
        "#Example\n",
        "\n",
        "{\n",
        "\n",
        "  \"goal\": \"Your helpful programming chatbot, help user to solve query and provide answer in json or dict format. If user asks other than programming content responsd with 'Im an Programming chatbot'\",\n",
        "\n",
        "  \"example_1\": \"\"\"\n",
        "\n",
        "  {\n",
        "    'user_query': 'what is python' # user input question | Provide or paste the user input here as it is without changing even a single word\n",
        "    'AI_answer': '' # provide you answer in this key. | As it a programming content provide anwswer\n",
        "  \"\"\"\n",
        "  },\n",
        "\n",
        "  {\n",
        "    'user_query': 'explain about IPL' # user input question | Provide or paste the user input here as it is without changing even a single word\n",
        "    'AI_answer': 'Im an Programming chatbot' # provide you answer in this key.  | respond with the message that your programming chatbot\n",
        "    \n",
        "  \"\"\"\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BHEb5VM0tvK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "hydt_yKPs5Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key = \"\""
      ],
      "metadata": {
        "id": "bQnEHK8I07HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "goal = \"\"\"\n",
        "Your a helpful assisstant, your job is to help user to solve query and provide answer in json or dict format. If user asks other than programming content responsd with 'Im an Programming chatbot'\n",
        "\"\"\"\n",
        "\n",
        "example = \"\"\"\n",
        "Example 1:\n",
        "  {\n",
        "    'user_query': 'what is python' # user input question | Provide or paste the user input here as it is without changing even a single word\n",
        "    'AI_answer': '' # provide you answer in this key. | As it a programming content provide anwswer\n",
        "  }\n",
        "\n",
        "Example 2:\n",
        "{\n",
        "  'user_query': 'explain about IPL' # user input question | Provide or paste the user input here as it is without changing even a single word\n",
        "  'AI_answer': 'Im an Programming chatbot' # provide you answer in this key\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "system_prompt = f\"Goal: {goal}\\n\\nExample: {example}\"\n"
      ],
      "metadata": {
        "id": "VqmKzoBR1stn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": system_prompt\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"explain how waves are formerd in sea\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "xksmc6Jt1EWi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI"
      ],
      "metadata": {
        "id": "hRnpr7NR2EIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(api_key=openai_key)"
      ],
      "metadata": {
        "id": "lmb3aO5E2bWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",  # or \"gpt-4\", \"gpt-4o\", etc.\n",
        "    messages=prompt,\n",
        "    temperature=0.7,\n",
        "    max_tokens=100,\n",
        ")\n"
      ],
      "metadata": {
        "id": "_3CDdC_m2iCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response.choices[0].message.content.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vhUrpvMz2s9r",
        "outputId": "34a28978-584d-48c6-adaf-421dca20ce8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"{\\n  'user_query': 'explain how waves are formerd in sea',\\n  'AI_answer': 'Im an Programming chatbot'\\n}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNPCba-c25Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "vd69N5crdeqD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Core Principles of a Good Prompt\n",
        "\n",
        "1. Be Clear and Specific\n",
        "\n",
        "- Clearly define the task.\n",
        "\n",
        "- Include context or constraints.\n",
        "\n",
        "- Specify the desired format/output.\n",
        "\n",
        "```\n",
        "❌ Bad:\n",
        "\n",
        "“Summarize this.”\n",
        "\n",
        "✅ Good:\n",
        "\n",
        "“Summarize the following text into 3 bullet points highlighting only the main arguments.”\n",
        "```"
      ],
      "metadata": {
        "id": "AIYf5gnOdh_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Bv3vaZEchG67"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How chatgpt understand or process the text"
      ],
      "metadata": {
        "id": "hxKGAQy-hIDC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Gokul was an Ai Engineer working in southern part of india located in coimbatore he has 5 years experince in the field of python along with AI."
      ],
      "metadata": {
        "id": "2xA0R68NdfF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Input Encoding (Tokenization)\n",
        "Every word (and even part of a word) is broken into tokens. For example:\n",
        "```\n",
        "[\"Gokul\", \"was\", \"an\", \"AI\", \"Engineer\", \"working\", \"in\", \"southern\", \"part\", \"of\", \"India\", \"located\", \"in\", \"Coimbatore\", \".\", \"He\", \"has\", \"5\", \"years\", \"experience\", \"in\", \"the\", \"field\", \"of\", \"Python\", \"along\", \"with\", \"AI\", \".\"]\n",
        "```\n",
        "\n",
        "But most transformers use subword tokenization (like Byte-Pair Encoding or WordPiece), so it may look like this internally:\n",
        "```\n",
        "[\"Gokul\", \"was\", \"an\", \"AI\", \"Engineer\", \"work\", \"##ing\", \"in\", \"south\", \"##ern\", ..., \"Coim\", \"##bato\", \"##re\"]\n",
        "```\n",
        " Why Subword? Helps handle new words, rare names, or spelling variations.\n",
        "\n",
        "\n",
        "##  2. Token Embeddings\n",
        "Each token is converted into a dense vector (say, 768 dimensions) using an embedding matrix.\n",
        "\n",
        "Example:\n",
        "\"Gokul\" → [0.12, -0.44, ..., 0.87]\n",
        "\n",
        "These embeddings capture:\n",
        "\n",
        "- Word meaning\n",
        "\n",
        "- Contextual usage\n",
        "\n",
        "- Semantic closeness (e.g., \"Engineer\" and \"Developer\" are near in space)\n",
        "\n",
        "## 3. Positional Encoding\n",
        "Since transformers don't have loops, position of each token is added (e.g., whether \"Gokul\" came first or last).\n",
        "```\n",
        "This helps the model understand grammar like:\n",
        "“Gokul was an engineer” vs “An engineer was Gokul”.\n",
        "```\n",
        "\n",
        "## 4. Passing Through Transformer Layers\n",
        "The embedded and position-aware tokens pass through multiple transformer blocks, each with:\n",
        "\n",
        "- Self-Attention:\n",
        "\n",
        "    Looks at all other tokens to figure out what to focus on.\n",
        "\n",
        "    → For “He”, the model attends to “Gokul” to know who \"He\" refers to.\n",
        "\n",
        "- Feedforward Layers:\n",
        "\n",
        "    Adds non-linearity and complexity.\n",
        "\n",
        "- Layer Norm & Residuals:\n",
        "    For stability and better learning.\n",
        "\n",
        "## 5. Attention Visualization\n",
        "Let's look at this part of your sentence:\n",
        "```\n",
        "\"He has 5 years experience\"\n",
        "```\n",
        "\n",
        "#### The attention mechanism sees:\n",
        "\n",
        "- “He” → highly connected to “Gokul”\n",
        "\n",
        "- “5 years” → connects with “experience”\n",
        "\n",
        "- “Experience” → strongly linked to “Python” and “AI”\n",
        "\n",
        "## 6. Final Representation\n",
        "After all transformer layers, each token has a contextual vector representing not just the word but its meaning in that sentence.\n",
        "\n",
        "For example:\n",
        "\n",
        "“AI” in “AI Engineer” has a different vector than “AI” in “along with AI”.\n",
        "\n",
        "## 7. Output (Based on Task)\n",
        "Depending on your goal, this final vector is used:\n",
        " - For summarization: The whole sentence vector is pooled and shortened.\n",
        "\n",
        " - For question answering: The model picks the answer span.\n",
        "\n",
        " - For understanding intent or generating a reply (as I do): The next tokens are predicted using all this context."
      ],
      "metadata": {
        "id": "IUSHTugkiwiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Thought:\n",
        "Modern AI models don’t just “see” words.\n",
        "\n",
        "They understand grammar, references, roles, and meanings using:\n",
        "\n",
        "\n",
        "✅ Tokens →\n",
        "✅ Embeddings →\n",
        "✅ Attention →\n",
        "✅ Context →\n",
        "✅ Output\n",
        "\n",
        "All without manually removing stopwords or hardcoded rules."
      ],
      "metadata": {
        "id": "BKnrlX0rnyez"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YBeONTNnnxwE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}