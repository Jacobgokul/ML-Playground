<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>Cross-Validation - ML Playground</title>
<style>
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;background:#f8fafc;color:#1e293b;line-height:1.7}
.top-bar{background:#0f172a;padding:14px 32px;display:flex;align-items:center;gap:16px;position:sticky;top:0;z-index:10}
.top-bar a{color:#94a3b8;text-decoration:none;font-size:14px;font-weight:600;transition:.15s}
.top-bar a:hover{color:#f1f5f9}
.top-bar .sep{color:#334155}
.top-bar .current{color:#60a5fa}
.container{max-width:900px;margin:0 auto;padding:40px 32px 80px}
h1{font-size:32px;font-weight:800;letter-spacing:-.8px;margin-bottom:8px;color:#0f172a}
.subtitle{font-size:16px;color:#64748b;margin-bottom:32px;border-bottom:2px solid #e2e8f0;padding-bottom:20px}
h2{font-size:22px;font-weight:700;margin:36px 0 14px;color:#0f172a;letter-spacing:-.3px}
h3{font-size:17px;font-weight:700;margin:24px 0 10px;color:#1e293b}
p{margin-bottom:14px;font-size:15px;color:#334155}
ul,ol{margin:0 0 16px 24px;font-size:15px;color:#334155}
li{margin-bottom:6px}
.card{background:#fff;border:1px solid #e2e8f0;border-radius:12px;padding:24px;margin:20px 0}
.card-title{font-size:14px;font-weight:700;color:#64748b;text-transform:uppercase;letter-spacing:.8px;margin-bottom:12px}
.formula{background:#0f172a;color:#e2e8f0;padding:20px 24px;border-radius:10px;font-family:'Courier New',monospace;font-size:15px;margin:16px 0;overflow-x:auto;white-space:pre;line-height:1.8}
.code{background:#0f172a;color:#e2e8f0;padding:20px 24px;border-radius:10px;font-family:'Courier New',monospace;font-size:13px;margin:16px 0;overflow-x:auto;white-space:pre;line-height:1.6}
.highlight{background:#eff6ff;border-left:4px solid #3b82f6;padding:16px 20px;border-radius:0 8px 8px 0;margin:16px 0}
.highlight p{margin:0;color:#1e40af;font-size:14px}
.warning{background:#fef3c7;border-left:4px solid #f59e0b;padding:16px 20px;border-radius:0 8px 8px 0;margin:16px 0}
.warning p{margin:0;color:#92400e;font-size:14px}
.grid{display:grid;grid-template-columns:1fr 1fr;gap:14px;margin:16px 0}
.grid-item{background:#fff;border:1px solid #e2e8f0;border-radius:10px;padding:18px}
.grid-item h4{font-size:14px;font-weight:700;margin-bottom:6px}
.grid-item p{font-size:13px;margin:0}
.tag{display:inline-block;padding:3px 10px;border-radius:20px;font-size:11px;font-weight:600;background:#f1f5f9;color:#475569;margin:2px}
.pros{color:#059669}.cons{color:#dc2626}
table{width:100%;border-collapse:collapse;margin:16px 0;font-size:14px}
th{background:#f1f5f9;padding:10px 14px;text-align:left;font-weight:700;border:1px solid #e2e8f0}
td{padding:10px 14px;border:1px solid #e2e8f0}
@media(max-width:700px){.container{padding:20px 16px 60px}.grid{grid-template-columns:1fr}h1{font-size:24px}}
</style>
</head>
<body>
<div class="top-bar">
<a href="../../index.html">ML Playground</a>
<span class="sep">/</span>
<span class="current">Cross-Validation</span>
</div>
<div class="container">

<h1>Cross-Validation</h1>
<p class="subtitle">Properly estimate model performance by training and testing on different subsets of your data.</p>

<h2>Why Cross-Validation?</h2>
<p>A single train-test split can be misleading. If your test set happens to be "easy", you'll overestimate performance. Cross-validation uses multiple splits to get a reliable, unbiased estimate of how your model will perform on unseen data.</p>

<div class="highlight"><p>A single 80/20 split gives you ONE accuracy number. 5-fold cross-validation gives you FIVE, plus a mean and standard deviation — much more trustworthy.</p></div>

<h2>Types of Cross-Validation</h2>

<h3>K-Fold Cross-Validation</h3>
<div class="formula">Data split into K equal folds:

Fold 1: [TEST] [Train] [Train] [Train] [Train]  → Score 1
Fold 2: [Train] [TEST] [Train] [Train] [Train]  → Score 2
Fold 3: [Train] [Train] [TEST] [Train] [Train]  → Score 3
Fold 4: [Train] [Train] [Train] [TEST] [Train]  → Score 4
Fold 5: [Train] [Train] [Train] [Train] [TEST]  → Score 5

Final Score = Mean(Score 1..5) ± Std(Score 1..5)</div>

<h3>Stratified K-Fold</h3>
<p>Same as K-Fold but ensures each fold has the same class distribution as the full dataset. Essential for imbalanced datasets where one class is rare.</p>

<h3>Leave-One-Out (LOO)</h3>
<p>K = N (number of samples). Each sample is used as test set once. Very thorough but computationally expensive. Best for very small datasets.</p>

<h3>Time Series Split</h3>
<p>For time-ordered data where future data can't be used to predict the past. Training set grows with each fold:</p>
<div class="formula">Fold 1: [Train] [Test] [----] [----] [----]
Fold 2: [Train] [Train] [Test] [----] [----]
Fold 3: [Train] [Train] [Train] [Test] [----]
Fold 4: [Train] [Train] [Train] [Train] [Test]</div>

<h2>Code Implementation</h2>
<div class="code">from sklearn.model_selection import (cross_val_score, KFold, StratifiedKFold,
                                      LeaveOneOut, TimeSeriesSplit)
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import load_iris
import numpy as np

X, y = load_iris(return_X_y=True)
model = RandomForestClassifier(n_estimators=100, random_state=42)

# --- K-Fold (5 folds) ---
kf = KFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=kf, scoring='accuracy')
print(f"K-Fold:      {scores.mean():.4f} ± {scores.std():.4f}")
print(f"  Per fold:  {scores}")

# --- Stratified K-Fold (preserves class distribution) ---
skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=skf, scoring='accuracy')
print(f"Stratified:  {scores.mean():.4f} ± {scores.std():.4f}")

# --- Leave-One-Out ---
loo = LeaveOneOut()
scores = cross_val_score(model, X, y, cv=loo, scoring='accuracy')
print(f"LOO:         {scores.mean():.4f} (150 folds)")

# --- Time Series Split ---
tscv = TimeSeriesSplit(n_splits=5)
scores = cross_val_score(model, X, y, cv=tscv, scoring='accuracy')
print(f"TimeSeries:  {scores.mean():.4f} ± {scores.std():.4f}")

# --- Shorthand (just pass k) ---
scores = cross_val_score(model, X, y, cv=10)  # 10-fold
print(f"10-Fold:     {scores.mean():.4f} ± {scores.std():.4f}")</div>

<h2>Which to Use?</h2>
<table>
<tr><th>Method</th><th>When to Use</th><th>K Value</th></tr>
<tr><td><strong>K-Fold</strong></td><td>General purpose, balanced classes</td><td>5 or 10</td></tr>
<tr><td><strong>Stratified K-Fold</strong></td><td>Imbalanced classes (always prefer this)</td><td>5 or 10</td></tr>
<tr><td><strong>Leave-One-Out</strong></td><td>Very small datasets (&lt;50 samples)</td><td>N</td></tr>
<tr><td><strong>Repeated K-Fold</strong></td><td>Need very stable estimates</td><td>5×10 repeats</td></tr>
<tr><td><strong>Time Series Split</strong></td><td>Time-ordered data (stock prices, weather)</td><td>5-10</td></tr>
</table>

<h2>Cross-Validation with Hyperparameter Tuning</h2>
<div class="code">from sklearn.model_selection import GridSearchCV

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 10, None]
}

# GridSearchCV uses cross-validation internally
grid_search = GridSearchCV(
    RandomForestClassifier(random_state=42),
    param_grid,
    cv=StratifiedKFold(n_splits=5),
    scoring='accuracy',
    n_jobs=-1
)
grid_search.fit(X, y)
print(f"Best params: {grid_search.best_params_}")
print(f"Best CV score: {grid_search.best_score_:.4f}")</div>

<div class="warning"><p>Never use cross-validation scores as final test scores. Always keep a completely separate holdout test set that is never used during training or hyperparameter tuning.</p></div>

</div>
</body>
</html>