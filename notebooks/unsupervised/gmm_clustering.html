<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1.0">
<title>GMM Clustering - ML Playground</title>
<style>
*{margin:0;padding:0;box-sizing:border-box}
body{font-family:-apple-system,BlinkMacSystemFont,'Segoe UI',Roboto,sans-serif;background:#f8fafc;color:#1e293b;line-height:1.7}
.top-bar{background:#0f172a;padding:14px 32px;display:flex;align-items:center;gap:16px;position:sticky;top:0;z-index:10}
.top-bar a{color:#94a3b8;text-decoration:none;font-size:14px;font-weight:600;transition:.15s}
.top-bar a:hover{color:#f1f5f9}
.top-bar .sep{color:#334155}
.top-bar .current{color:#60a5fa}
.container{max-width:900px;margin:0 auto;padding:40px 32px 80px}
h1{font-size:32px;font-weight:800;letter-spacing:-.8px;margin-bottom:8px;color:#0f172a}
.subtitle{font-size:16px;color:#64748b;margin-bottom:32px;border-bottom:2px solid #e2e8f0;padding-bottom:20px}
h2{font-size:22px;font-weight:700;margin:36px 0 14px;color:#0f172a;letter-spacing:-.3px}
h3{font-size:17px;font-weight:700;margin:24px 0 10px;color:#1e293b}
p{margin-bottom:14px;font-size:15px;color:#334155}
ul,ol{margin:0 0 16px 24px;font-size:15px;color:#334155}
li{margin-bottom:6px}
.card{background:#fff;border:1px solid #e2e8f0;border-radius:12px;padding:24px;margin:20px 0}
.card-title{font-size:14px;font-weight:700;color:#64748b;text-transform:uppercase;letter-spacing:.8px;margin-bottom:12px}
.formula{background:#0f172a;color:#e2e8f0;padding:20px 24px;border-radius:10px;font-family:'Courier New',monospace;font-size:15px;margin:16px 0;overflow-x:auto;white-space:pre;line-height:1.8}
.code{background:#0f172a;color:#e2e8f0;padding:20px 24px;border-radius:10px;font-family:'Courier New',monospace;font-size:13px;margin:16px 0;overflow-x:auto;white-space:pre;line-height:1.6}
.highlight{background:#eff6ff;border-left:4px solid #3b82f6;padding:16px 20px;border-radius:0 8px 8px 0;margin:16px 0}
.highlight p{margin:0;color:#1e40af;font-size:14px}
.warning{background:#fef3c7;border-left:4px solid #f59e0b;padding:16px 20px;border-radius:0 8px 8px 0;margin:16px 0}
.warning p{margin:0;color:#92400e;font-size:14px}
.grid{display:grid;grid-template-columns:1fr 1fr;gap:14px;margin:16px 0}
.grid-item{background:#fff;border:1px solid #e2e8f0;border-radius:10px;padding:18px}
.grid-item h4{font-size:14px;font-weight:700;margin-bottom:6px}
.grid-item p{font-size:13px;margin:0}
.tag{display:inline-block;padding:3px 10px;border-radius:20px;font-size:11px;font-weight:600;background:#f1f5f9;color:#475569;margin:2px}
.pros{color:#059669}.cons{color:#dc2626}
table{width:100%;border-collapse:collapse;margin:16px 0;font-size:14px}
th{background:#f1f5f9;padding:10px 14px;text-align:left;font-weight:700;border:1px solid #e2e8f0}
td{padding:10px 14px;border:1px solid #e2e8f0}
@media(max-width:700px){.container{padding:20px 16px 60px}.grid{grid-template-columns:1fr}h1{font-size:24px}}
</style>
</head>
<body>
<div class="top-bar">
<a href="../../index.html">ML Playground</a>
<span class="sep">/</span>
<span class="current">GMM Clustering</span>

<a href="https://github.com/Jacobgokul/ML-Playground/blob/main/machine_learning/unsupervised/gmm_clustering.ipynb" target="_blank" style="color:#94a3b8;text-decoration:none;font-size:13px;font-weight:600;display:flex;align-items:center;gap:6px;margin-left:auto;transition:.15s" onmouseover="this.style.color='#f1f5f9'" onmouseout="this.style.color='#94a3b8'"><svg width="14" height="14" viewBox="0 0 16 16" fill="currentColor" style="vertical-align:-2px"><path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0016 8c0-4.42-3.58-8-8-8z"/></svg> View Notebook</a>
</div>
<div class="container">

<h1>Gaussian Mixture Model (GMM)</h1>
<p class="subtitle">A probabilistic clustering algorithm that models data as a mixture of multiple Gaussian distributions, providing soft cluster assignments.</p>

<h2>What It Is</h2>
<p>GMM assumes data is generated from a mixture of several Gaussian (normal) distributions, each representing a cluster. Unlike K-Means which assigns each point to exactly one cluster, GMM gives a probability of belonging to each cluster (soft clustering).</p>

<div class="highlight"><p>GMM is the go-to algorithm when clusters overlap or when you need probability estimates for cluster membership rather than hard assignments.</p></div>

<h2>How It Works</h2>
<p>GMM uses the Expectation-Maximization (EM) algorithm to iteratively estimate the parameters of each Gaussian distribution.</p>

<div class="card">
<div class="card-title">Algorithm Steps</div>
<ol>
<li><strong>Initialize parameters</strong> &mdash; Set the number of clusters K. Randomly initialize the mean, covariance, and mixing weight for each Gaussian.</li>
<li><strong>E-Step (Expectation)</strong> &mdash; For each data point, compute the probability it belongs to each Gaussian cluster using the multivariate Gaussian PDF.</li>
<li><strong>M-Step (Maximization)</strong> &mdash; Update the mean, covariance, and weight of each Gaussian to maximize the likelihood of the observed data.</li>
<li><strong>Repeat</strong> until parameters converge (stop changing significantly).</li>
</ol>
</div>

<h3>Parameters of Each Gaussian</h3>
<div class="formula">Each Gaussian cluster has three parameters:
  Mean (mu)       = center of the cluster
  Covariance (Sigma) = shape and spread of the cluster
  Weight (pi)     = proportion of data belonging to this cluster

Sum of all weights = 1</div>

<h2>Code: Fit GMM</h2>
<div class="code">import numpy as np
import matplotlib.pyplot as plt
from sklearn.mixture import GaussianMixture
from sklearn.datasets import make_blobs
from sklearn.preprocessing import StandardScaler

# Generate synthetic data with 3 clusters
X, _ = make_blobs(n_samples=300, centers=3, cluster_std=1.2, random_state=42)

# Standardize features (important for GMM)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Plot raw data
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], s=30, alpha=0.6)
plt.title("Generated Data for Clustering")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.show()</div>

<h3>Train and Predict</h3>
<div class="code"># Define and fit the GMM model
gmm = GaussianMixture(n_components=3, covariance_type='full', random_state=42)
gmm.fit(X_scaled)

# Predict cluster labels (hard assignment)
labels = gmm.predict(X_scaled)

# Get soft probabilities for each cluster
probabilities = gmm.predict_proba(X_scaled)

# Plot clusters with GMM labels
plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=labels, cmap='viridis', s=40, alpha=0.7)
plt.scatter(gmm.means_[:, 0], gmm.means_[:, 1], c='red', marker='X', s=200, label='Centroids')
plt.title("GMM Clustering Results")
plt.xlabel("Feature 1")
plt.ylabel("Feature 2")
plt.legend()
plt.show()</div>

<h3>Inspect Learned Parameters</h3>
<div class="code">print("Cluster Weights (pi):", gmm.weights_)
print("Cluster Means (mu):", gmm.means_)
print("Cluster Covariances (Sigma):", gmm.covariances_)</div>

<h2>K-Means vs GMM</h2>
<table>
<tr><th>Feature</th><th>K-Means</th><th>GMM</th></tr>
<tr><td>Assignment</td><td>Hard (one cluster per point)</td><td>Soft (probability per cluster)</td></tr>
<tr><td>Cluster shape</td><td>Spherical only</td><td>Elliptical (any covariance shape)</td></tr>
<tr><td>Algorithm</td><td>Lloyd's iteration</td><td>Expectation-Maximization</td></tr>
<tr><td>Speed</td><td>Faster</td><td>Slower (more parameters to estimate)</td></tr>
<tr><td>Outlier handling</td><td>Assigns outliers to nearest cluster</td><td>Outliers get low probability for all clusters</td></tr>
</table>

<h2>When to Use GMM</h2>
<table>
<tr><th>Good For</th><th>Not Ideal For</th></tr>
<tr><td>Overlapping clusters</td><td>Very high-dimensional data (many parameters)</td></tr>
<tr><td>Need probability estimates, not just labels</td><td>When clusters are well-separated (K-Means is simpler)</td></tr>
<tr><td>Elliptical/non-spherical cluster shapes</td><td>Very large datasets (EM can be slow)</td></tr>
<tr><td>Density estimation, anomaly detection</td><td>When you need deterministic results</td></tr>
</table>

<div class="warning"><p>GMM is sensitive to initialization and can converge to local optima. Always use multiple initializations (n_init parameter) and pick the result with the highest likelihood. Standardize your features before fitting.</p></div>

<h2>Key Parameters</h2>
<ul>
<li><strong>n_components</strong> &mdash; Number of Gaussian clusters</li>
<li><strong>covariance_type</strong> &mdash; 'full' (each cluster has its own covariance), 'tied', 'diag', 'spherical'</li>
<li><strong>n_init</strong> &mdash; Number of initializations (default 1, increase for stability)</li>
<li><strong>random_state</strong> &mdash; Seed for reproducibility</li>
</ul>

<p><span class="tag">Unsupervised</span> <span class="tag">Clustering</span> <span class="tag">Probabilistic</span> <span class="tag">EM Algorithm</span></p>

</div>
</body>
</html>