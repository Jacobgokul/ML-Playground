{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOZGODMUz3TwK9YV3MRA/uO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jacobgokul/ML-Playground/blob/main/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNNs are designed for sequential data (e.g., time series, speech, text). Unlike traditional neural networks, RNNs have loops that allow them to store information from previous time steps, making them suitable for handling dependencies in sequences."
      ],
      "metadata": {
        "id": "nC_c4y6grL-V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#How RNN Works Step by Step\n",
        "\n",
        "Input Sequence: The input is processed one step at a time.\n",
        "\n",
        "Hidden State: At each step, the model updates a hidden state that stores information about past inputs.\n",
        "\n",
        "Recurrent Connection: The output from the previous step is passed as an input to the next step.\n",
        "\n",
        "Output: After processing all steps, the network provides an output (classification, prediction, etc.)."
      ],
      "metadata": {
        "id": "GHYwkpQescuV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y3ifvYYjrHKd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the IMDB dataset\n",
        "vocab_size = 10000  # Consider top 10,000 words only\n",
        "max_length = 200    # Max review length (truncate/pad to this length)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1d2cXQ8ksUa2",
        "outputId": "83990b4d-bc92-4322-9a44-f553254b4bbc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayKj1QL-tYxU",
        "outputId": "da932630-8ba5-41ae-df07-5de863f93504"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWwhrd3qta7N",
        "outputId": "5ac2095a-2c72-4194-9bc3-a0a081a847b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jeS4gFn_tuhO",
        "outputId": "cd9c715f-eefe-4335-d361-b66f4f3c1caa"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   5,   25,  100, ...,   19,  178,   32],\n",
              "       [   0,    0,    0, ...,   16,  145,   95],\n",
              "       [   0,    0,    0, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [   0,    0,    0, ...,    4, 3586,    2],\n",
              "       [   0,    0,    0, ...,   12,    9,   23],\n",
              "       [   0,    0,    0, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Pad sequences to make all inputs of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=max_length)\n",
        "x_test = pad_sequences(x_test, maxlen=max_length)\n"
      ],
      "metadata": {
        "id": "tZP9tcY2tfB5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=32, input_length=max_length),  # Word embeddings\n",
        "    SimpleRNN(units=32, return_sequences=False),  # Recurrent layer\n",
        "    Dense(units=1, activation='sigmoid')  # Output layer for binary classification\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzeP1h4Ttim2",
        "outputId": "db64b19b-c955-44ce-8ed7-e94a41a03eab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Compile the Model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Ngb55LO8uI-Y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train the Model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0h3jAkDuJdw",
        "outputId": "bbec9930-78e8-48cb-d58e-cc0fa3dc1d84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 24ms/step - accuracy: 0.5996 - loss: 0.6477 - val_accuracy: 0.7994 - val_loss: 0.4471\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.8415 - loss: 0.3735 - val_accuracy: 0.8250 - val_loss: 0.4031\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9130 - loss: 0.2264 - val_accuracy: 0.8332 - val_loss: 0.4012\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 21ms/step - accuracy: 0.9584 - loss: 0.1204 - val_accuracy: 0.8271 - val_loss: 0.4751\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 19ms/step - accuracy: 0.9843 - loss: 0.0574 - val_accuracy: 0.8257 - val_loss: 0.5518\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e01fbd12b10>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Evaluate the Model\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3nBMwKyuN4D",
        "outputId": "a3f1b8e8-4171-4cc4-da2f-4e81811ea808"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.8277 - loss: 0.5536\n",
            "Test Accuracy: 0.8257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "RZ761B1vua8s"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pick a sample review from the test set\n",
        "sample_review = x_test[1]  # First review in the test set\n",
        "sample_review = np.expand_dims(sample_review, axis=0)  # Reshape to match model input\n",
        "\n",
        "# Predict sentiment\n",
        "prediction = model.predict(sample_review)\n",
        "\n",
        "# Interpret result\n",
        "if prediction[0] > 0.5:\n",
        "    print(\"Predicted Sentiment: Positive 😊\")\n",
        "else:\n",
        "    print(\"Predicted Sentiment: Negative 😢\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5xCkfZ2uYyv",
        "outputId": "0f39362d-7897-4a7d-ce26-9fab73c408aa"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "Predicted Sentiment: Positive 😊\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uT_uLum1uvUP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}